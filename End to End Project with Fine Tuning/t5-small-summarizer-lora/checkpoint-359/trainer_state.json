{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 359,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.027855153203342618,
      "grad_norm": 11.642440795898438,
      "learning_rate": 0.000977715877437326,
      "loss": 9.7837,
      "step": 10
    },
    {
      "epoch": 0.055710306406685235,
      "grad_norm": 0.9756042957305908,
      "learning_rate": 0.0009498607242339833,
      "loss": 2.1413,
      "step": 20
    },
    {
      "epoch": 0.08356545961002786,
      "grad_norm": 0.333683580160141,
      "learning_rate": 0.0009220055710306407,
      "loss": 1.2728,
      "step": 30
    },
    {
      "epoch": 0.11142061281337047,
      "grad_norm": 0.3131815791130066,
      "learning_rate": 0.0008941504178272981,
      "loss": 1.1241,
      "step": 40
    },
    {
      "epoch": 0.1392757660167131,
      "grad_norm": 0.32915225625038147,
      "learning_rate": 0.0008662952646239555,
      "loss": 1.0953,
      "step": 50
    },
    {
      "epoch": 0.1671309192200557,
      "grad_norm": 0.3137911856174469,
      "learning_rate": 0.0008384401114206128,
      "loss": 1.036,
      "step": 60
    },
    {
      "epoch": 0.19498607242339833,
      "grad_norm": 0.28561556339263916,
      "learning_rate": 0.0008105849582172702,
      "loss": 1.0291,
      "step": 70
    },
    {
      "epoch": 0.22284122562674094,
      "grad_norm": 0.2822289764881134,
      "learning_rate": 0.0007827298050139275,
      "loss": 1.0358,
      "step": 80
    },
    {
      "epoch": 0.25069637883008355,
      "grad_norm": 0.2737785577774048,
      "learning_rate": 0.000754874651810585,
      "loss": 0.9173,
      "step": 90
    },
    {
      "epoch": 0.2785515320334262,
      "grad_norm": 0.311545193195343,
      "learning_rate": 0.0007270194986072424,
      "loss": 0.9439,
      "step": 100
    },
    {
      "epoch": 0.3064066852367688,
      "grad_norm": 0.27686676383018494,
      "learning_rate": 0.0006991643454038998,
      "loss": 1.0057,
      "step": 110
    },
    {
      "epoch": 0.3342618384401114,
      "grad_norm": 0.26875561475753784,
      "learning_rate": 0.000671309192200557,
      "loss": 0.9088,
      "step": 120
    },
    {
      "epoch": 0.362116991643454,
      "grad_norm": 0.2238752543926239,
      "learning_rate": 0.0006434540389972145,
      "loss": 0.972,
      "step": 130
    },
    {
      "epoch": 0.38997214484679665,
      "grad_norm": 0.48962464928627014,
      "learning_rate": 0.0006155988857938719,
      "loss": 0.8907,
      "step": 140
    },
    {
      "epoch": 0.4178272980501393,
      "grad_norm": 0.2578357756137848,
      "learning_rate": 0.0005877437325905293,
      "loss": 0.9777,
      "step": 150
    },
    {
      "epoch": 0.4456824512534819,
      "grad_norm": 0.2686097025871277,
      "learning_rate": 0.0005598885793871866,
      "loss": 0.9729,
      "step": 160
    },
    {
      "epoch": 0.4735376044568245,
      "grad_norm": 0.27744022011756897,
      "learning_rate": 0.000532033426183844,
      "loss": 0.9319,
      "step": 170
    },
    {
      "epoch": 0.5013927576601671,
      "grad_norm": 0.27074939012527466,
      "learning_rate": 0.0005041782729805015,
      "loss": 0.9101,
      "step": 180
    },
    {
      "epoch": 0.5292479108635098,
      "grad_norm": 0.24538567662239075,
      "learning_rate": 0.0004763231197771588,
      "loss": 0.9788,
      "step": 190
    },
    {
      "epoch": 0.5571030640668524,
      "grad_norm": 0.30164700746536255,
      "learning_rate": 0.0004484679665738162,
      "loss": 0.981,
      "step": 200
    },
    {
      "epoch": 0.584958217270195,
      "grad_norm": 0.25004857778549194,
      "learning_rate": 0.0004206128133704735,
      "loss": 0.9962,
      "step": 210
    },
    {
      "epoch": 0.6128133704735376,
      "grad_norm": 0.2353437840938568,
      "learning_rate": 0.00039275766016713096,
      "loss": 0.9494,
      "step": 220
    },
    {
      "epoch": 0.6406685236768802,
      "grad_norm": 0.27626946568489075,
      "learning_rate": 0.0003649025069637883,
      "loss": 0.9067,
      "step": 230
    },
    {
      "epoch": 0.6685236768802229,
      "grad_norm": 0.24123181402683258,
      "learning_rate": 0.00033704735376044573,
      "loss": 0.9112,
      "step": 240
    },
    {
      "epoch": 0.6963788300835655,
      "grad_norm": 0.2547541856765747,
      "learning_rate": 0.00030919220055710306,
      "loss": 0.9267,
      "step": 250
    },
    {
      "epoch": 0.724233983286908,
      "grad_norm": 0.25121596455574036,
      "learning_rate": 0.0002813370473537605,
      "loss": 0.948,
      "step": 260
    },
    {
      "epoch": 0.7520891364902507,
      "grad_norm": 0.23472532629966736,
      "learning_rate": 0.00025348189415041783,
      "loss": 0.918,
      "step": 270
    },
    {
      "epoch": 0.7799442896935933,
      "grad_norm": 0.21480511128902435,
      "learning_rate": 0.00022562674094707522,
      "loss": 0.8925,
      "step": 280
    },
    {
      "epoch": 0.807799442896936,
      "grad_norm": 0.26017072796821594,
      "learning_rate": 0.0001977715877437326,
      "loss": 1.0118,
      "step": 290
    },
    {
      "epoch": 0.8356545961002786,
      "grad_norm": 0.27004745602607727,
      "learning_rate": 0.00016991643454038996,
      "loss": 0.9254,
      "step": 300
    },
    {
      "epoch": 0.8635097493036211,
      "grad_norm": 0.2927294075489044,
      "learning_rate": 0.00014206128133704735,
      "loss": 0.9528,
      "step": 310
    },
    {
      "epoch": 0.8913649025069638,
      "grad_norm": 0.30924805998802185,
      "learning_rate": 0.00011420612813370473,
      "loss": 1.0527,
      "step": 320
    },
    {
      "epoch": 0.9192200557103064,
      "grad_norm": 0.2563154399394989,
      "learning_rate": 8.635097493036212e-05,
      "loss": 0.9649,
      "step": 330
    },
    {
      "epoch": 0.947075208913649,
      "grad_norm": 0.25749334692955017,
      "learning_rate": 5.84958217270195e-05,
      "loss": 0.9937,
      "step": 340
    },
    {
      "epoch": 0.9749303621169917,
      "grad_norm": 0.2756902277469635,
      "learning_rate": 3.064066852367688e-05,
      "loss": 0.8695,
      "step": 350
    }
  ],
  "logging_steps": 10,
  "max_steps": 359,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 391167350931456.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
